{
  
    
        "post0": {
            "title": "Zero-shot classification with DOTA 2 in-game chats",
            "content": "Imports and utilities . import os import random import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns from transformers import AutoTokenizer, pipeline from transformers import AutoModelForSeq2SeqLM from transformers import AutoModelForSequenceClassification def zeroshot_classifier(): # Only works with English text tokenizer = AutoTokenizer .from_pretrained(&quot;facebook/bart-large-mnli&quot;) model = AutoModelForSequenceClassification .from_pretrained(&quot;facebook/bart-large-mnli&quot;) return pipeline(task=&#39;zero-shot-classification&#39;, model=model, tokenizer=tokenizer) plt.rcParams.update({&#39;font.size&#39;: 18, &quot;font.family&quot;: &quot;Times&quot;}) . Example 1: Reasoning or personal impression? . This is an example taken from Fiacco &amp; Rosé (2018). . Suppose you want to classify a text as a causal reasoning, a evaluation reasoning or a personal impression. . If someone says . &quot;Use of coal increases pollution&quot;, we expect the label to be causal reasoning. | &quot;Use of wind power may not be reliable throughtout the year&quot;, we expect the label to be evaluation reasoning. | &quot;I prefer coal power&quot;, we expect the label to be personal impression. | . Of course, these are not completely exclusive classes and could be better conceived to be exclusive, but suppose these are exclusive. . We can use a pre-trained model that is able to perform zero-shot learning and generate labels without any previous training data: . pipe = zeroshot_classifier() some_texts = [&quot;Use of coal increases pollution&quot;, &quot;Use of wind power may not be reliable throughout the year&quot;, &quot;I prefer coal power&quot;] candidate_labels = [&#39;causal reasoning&#39;, &#39;evaluation reasoning&#39;, &#39;personal impression&#39;] predictions = pipe(some_texts, candidate_labels=candidate_labels) . fig, ax = plt.subplots(nrows=3, figsize=(6,10)) for i, p in enumerate(predictions): sns.barplot(y=&#39;labels&#39;, x=&#39;scores&#39;, data=p, ax=ax[i], order=candidate_labels) ax[i].set_title(p[&#39;sequence&#39;][:50]) fig.tight_layout() . Why does this work? . I suggest you read the description of the model we are using here, they answer this question in very simply. . If you want to read my own (shorter) explanation of their explanation, here it is: . To understand the explanation, you need to know what is a NLI (Natural language inference) dataset. There are a few different NLI datasets out there, for example SNLI and MultiNLI are the most famous ones. In the task of these datasets, there is two pieces of texts, a premise and a hypotehsis. The option of labels are entailment (when the hypothesis confirms the premise), contradiction (when the hypothesis denies the premise), and neutral. Check some examples here. Some people call NLI&#39;s task as the entailment classification task. . The MultiNLI dataset is huge and enables robust algorithm architectures to produce very good models that can be transferred to other semantically similar tasks. . Suppose the model does a great job at the entailment task. Given our set of three candidate_labels, zero-shot learning with can be leveraged in the following way. Take the input text as the premise. For each ith candidate_labels, turn the into &quot;This sentence is about {i}&quot; and that is used as our hypothesis, predict the entailment of this hypothesis. Finally, transform the output to generate a probability for each candidate_label. . Let&#39;s go through another example to see it in action in a harder context. . Example 2: DOTA-2 in-game chats . a. Load the data . df = pd.read_csv(&#39;~/Downloads/dota2_chat_messages.csv&#39;, nrows=100) df[&#39;text&#39;] = df[&#39;text&#39;].fillna(&#39;&#39;) print(&#39;Previous mean length of text&#39;, df[&#39;text&#39;].apply(lambda x: len(x)).mean()) print(&#39;Removing 1% outliers of really big texts...&#39;) max_size_message = int(df[&#39;text&#39;].apply(len).quantile(.99)) df[&#39;text&#39;] = df[&#39;text&#39;].apply(lambda x: x[:max_size_message]) print(&#39;Mean length of text&#39;, df[&#39;text&#39;].apply(lambda x: len(x)).mean(), &#39; n n&#39;) print(df.head(15)) . Previous mean length of text 11.83 Removing 1% outliers of really big texts... Mean length of text 11.72 match time slot text 0 0 1005.12122 9 ладно гг 1 0 1005.85442 9 изи 2 0 1008.65372 9 од 3 0 1010.51992 9 ебаный 4 0 1013.91912 9 мусор на войде 5 0 1800.31402 9 мусор 6 0 1801.71882 9 на войде 7 0 1802.98982 9 репорт 8 0 1808.40822 9 100% 9 1 -131.14018 0 twitch.tv/rage_channel 10 1 -121.60481 0 https://www.twitch.tv/rage_channel 11 1 244.47367 7 2 даша подряд 12 1 249.93900 7 баша 13 1 255.00443 4 где даша? 14 1 261.20293 4 даша домой . df_sample = df.sample(30) . b. Translate to English . def translator(src: str, dest: str): src = src.lower() dest = dest.lower() tokenizer = AutoTokenizer .from_pretrained(f&quot;Helsinki-NLP/opus-mt-{src}-{dest}&quot;) model = AutoModelForSeq2SeqLM .from_pretrained(f&quot;Helsinki-NLP/opus-mt-{src}-{dest}&quot;) return pipeline(task=&#39;translation&#39;, model=model, tokenizer=tokenizer) translate = translator(&#39;ru&#39;, &#39;en&#39;) . %%time translated_text = translate([t[:max_size_message] for t in list(df_sample[&#39;text&#39;])]) df_sample[&#39;text_en&#39;] = [t[&#39;translation_text&#39;] for t in translated_text] . CPU times: user 2min 2s, sys: 1min 7s, total: 3min 9s Wall time: 2min 45s . df_sample.head(10) . match time slot text text_en . 82 4 | 228.94412 | 9 | у тебя мозг | You have a brain. | . 1 0 | 1005.85442 | 9 | изи | Easy | . 41 3 | 131.36794 | 6 | ТВОЯ МАТЬ ШЛЮ,ХА | You&#39;re gonna be kidding me. | . 37 2 | 2263.36970 | 2 | lol | lol | . 17 1 | 690.66473 | 6 | шок | Shock. | . 4 0 | 1013.91912 | 9 | мусор на войде | There&#39;s garbage in the door. | . 27 2 | 1281.95360 | 4 | HAHAH | HAHAH | . 95 4 | 1899.71342 | 3 | ебать у нас миде р рак | We&#39;ve got a fuckin&#39; midd r cancer. | . 74 4 | 135.73355 | 9 | мде | Yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah... | . 49 3 | 2212.78120 | 3 | vac d o l b a e b | vac d o l b a e b | . c. Load zero-shot classifier from Huggingface&#39;s transformers library . pipe = zeroshot_classifier() . d. Define your candidate labels . candidate_labels = [&#39;chitchat&#39;, &#39;game features&#39;, &#39;coordination&#39;, &#39;toxic offense&#39;, &#39;gender discrimination&#39;, &#39;religious intolerance&#39;, &#39;racism&#39;] . e. Generate and explore predictions . %%time predictions = pipe(list(df_sample[&#39;text_en&#39;]), candidate_labels=candidate_labels) predictions[0] . CPU times: user 4min 5s, sys: 29.9 s, total: 4min 35s Wall time: 4min 39s . {&#39;sequence&#39;: &#39;You have a brain.&#39;, &#39;labels&#39;: [&#39;coordination&#39;, &#39;chitchat&#39;, &#39;game features&#39;, &#39;gender discrimination&#39;, &#39;religious intolerance&#39;, &#39;racism&#39;, &#39;toxic offense&#39;], &#39;scores&#39;: [0.2801738679409027, 0.1728963702917099, 0.1706610769033432, 0.12368270754814148, 0.08645886927843094, 0.08541402220726013, 0.08071308583021164]} . labels = [] for p in predictions: labels.append(p[&#39;labels&#39;][np.argmax(p[&#39;scores&#39;])]) df_sample[&#39;label&#39;] = labels df_sample . match time slot text text_en label . 82 4 | 228.94412 | 9 | у тебя мозг | You have a brain. | coordination | . 1 0 | 1005.85442 | 9 | изи | Easy | chitchat | . 41 3 | 131.36794 | 6 | ТВОЯ МАТЬ ШЛЮ,ХА | You&#39;re gonna be kidding me. | toxic offense | . 37 2 | 2263.36970 | 2 | lol | lol | chitchat | . 17 1 | 690.66473 | 6 | шок | Shock. | toxic offense | . 4 0 | 1013.91912 | 9 | мусор на войде | There&#39;s garbage in the door. | toxic offense | . 27 2 | 1281.95360 | 4 | HAHAH | HAHAH | chitchat | . 95 4 | 1899.71342 | 3 | ебать у нас миде р рак | We&#39;ve got a fuckin&#39; midd r cancer. | toxic offense | . 74 4 | 135.73355 | 9 | мде | Yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah... | chitchat | . 49 3 | 2212.78120 | 3 | vac d o l b a e b | vac d o l b a e b | coordination | . 44 3 | 145.63110 | 0 | ты это антимагу написаЛ? | Did you write that anti-maga? | gender discrimination | . 6 0 | 1801.71882 | 9 | на войде | at the entrance | coordination | . 9 1 | -131.14018 | 0 | twitch.tv/rage_channel | Twitch.tv/range_channel | chitchat | . 29 2 | 1563.18490 | 0 | fast and furious | Fast and furious | game features | . 48 3 | 2199.00090 | 7 | WAC | WAC | coordination | . 15 1 | 597.98733 | 4 | долбоеб сука на дизрапторе | Fucking bitch on disraptor. | toxic offense | . 64 4 | 7.53150 | 8 | тебе всё равно фиаско братан) | You&#39;re still a fiasco, bro. | toxic offense | . 28 2 | 1559.05260 | 0 | yeah | Yeah, yeah, yeah, yeah, yeah, yeah, yeah, yeah... | chitchat | . 18 1 | 700.72893 | 0 | https://www.twitch.tv/rage_channel | https://www.twitch.tv/range_channel | coordination | . 65 4 | 37.59082 | 5 | wtf | wtf | toxic offense | . 14 1 | 261.20293 | 4 | даша домой | I&#39;m gonna give you a ride home. | coordination | . 80 4 | 228.94412 | 9 | нахуй иди | Fuck you. | toxic offense | . 68 4 | 38.15735 | 8 | :D | :D | chitchat | . 71 4 | 99.94226 | 1 | боже | Oh, my God. | toxic offense | . 53 3 | 2250.84410 | 4 | + | + | coordination | . 69 4 | 38.15735 | 3 | ласт пиком троля | The power of the spade of the throne | coordination | . 63 4 | -4.46558 | 8 | ну и?))) | What do you mean? ))))) | chitchat | . 54 3 | 2289.84370 | 0 | )) | ))) | coordination | . 50 3 | 2227.56480 | 7 | reportim ego? | Reportim ego? | toxic offense | . 96 4 | 1914.43022 | 5 | ах ты крыса мелкая | You little rat. | toxic offense | . how_many_to_plot = 10 fig, ax = plt.subplots(nrows=how_many_to_plot, figsize=(6,30)) for i, p in enumerate(random.sample(predictions, how_many_to_plot)): sns.barplot(y=&#39;labels&#39;, x=&#39;scores&#39;, data=p, ax=ax[i], order=candidate_labels) ax[i].set_title(p[&#39;sequence&#39;][:50]) fig.tight_layout() . In case you want to know more about zero-shot learning, I encourage you to go through the following material: . https://joeddav.github.io/blog/2020/05/29/ZSL.html | https://arxiv.org/abs/1909.00161 | https://www.deeplearningbook.org/contents/representation.html (Section 15.2) | https://www.aaai.org/Papers/AAAI/2008/AAAI08-132.pdf | . As a takeaway, I think a well designed zero-shot classifier (with good candidate labels) can be game-changing tool for several AI projects. . One use case is for example &quot;expert systems&quot;, where you generate these output probabilities for classes that you understand as intermediary features that you provide to a rule-based decision-making mechanism. Then you are able to write things like &quot;if causal_reasoning is high, do the action A; if evaluation_reasoning is high do the action B&quot;. I think there has some research opportunity with zero-shot learning as a feature engineering step because with this kind of system, although features are computed from black box models, your features are abstractions that you can understand and explain. Also, if you build candidate_labels using some theory, that is great for you because you have more evidence to back up your design. . The main issue I see with this is how can we evaluate if the zero-shot labels are good. Well, one way to measure is by letting the model compute several labels, and then you or another person can label manually. With your labels and the zero-shot ones, you can use Cohen&#39;s Kappa as your agreement level. That, however, is not scalable when you are testing several candidate_labels. . If you see interesting use cases for zero-shot learning, or want to interact/discuss about this notebook, please comment below!! .",
            "url": "https://adaj.github.io/blog/2021/11/27/Zero-shot-classification-with-DOTA-2-in-game-chats.html",
            "relUrl": "/2021/11/27/Zero-shot-classification-with-DOTA-2-in-game-chats.html",
            "date": " • Nov 27, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://adaj.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://adaj.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}